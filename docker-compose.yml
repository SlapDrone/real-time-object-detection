version: '3.8'

services:
  train_gpu:
    build: 
      dockerfile: ./Dockerfile.gpu
    volumes:
      - .:/usr/app
    # run continuously in background
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    ports:
      # Jupyter
      - 8888:8888
      # Dask cluster
      - 8787:8787
      # Tensorboard
      - 8686:8686
      - 6006:6006
      # MLFlow
      - 5000:5000
    expose:
      - 5000
    command:  bash -c "nohup poetry run poe track & poetry run poe jn & tail -f /dev/null"
    environment:
      - TESTING=0
      - LOCAL_DEV=1
      - MLFLOW_TRACKING_URI=http://0.0.0.0:5000
    container_name: train_gpu_container
  train_cpu:
    build: 
      dockerfile: ./Dockerfile.cpu
    volumes:
      - .:/usr/app
    ports:
      # Jupyter
      - 8888:8888
      # Dask cluster
      - 8787:8787
      # Tensorboard
      - 8686:8686
      - 6006:6006
      # MLFlow
      - 5000:5000
    expose:
      - 5000
    command:  bash -c "nohup poetry run poe track & poetry run poe jn & tail -f /dev/null"
    environment:
      - TESTING=0
      - LOCAL_DEV=1
      - MLFLOW_TRACKING_URI=http://0.0.0.0:5000
    container_name: train_cpu_container