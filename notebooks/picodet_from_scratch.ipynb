{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ef6bdf0",
   "metadata": {},
   "source": [
    "# picodet from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c17ea0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Sequence, Optional, Union\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pydantic.dataclasses import dataclass\n",
    "from pydantic import Field\n",
    "from mmcv.cnn import ConvModule\n",
    "from mmdet.models.utils import make_divisible\n",
    "from mmcv.runner import BaseModule\n",
    "\n",
    "from src.esnet import ESNet\n",
    "from src.csppan import ChannelEqualiser, DarknetBottleneck, CSPLayer, CSPPAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f2aed1",
   "metadata": {},
   "source": [
    "## Backbone: ESNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eee5d6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 9, 12]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/pypoetry/virtualenvs/dev-sZr6PvLR-py3.9/lib/python3.9/site-packages/mmcv/cnn/bricks/hsigmoid.py:31: UserWarning: In MMCV v1.4.4, we modified the default value of args to align with PyTorch official. Previous Implementation: Hsigmoid(x) = min(max((x + 1) / 2, 0), 1). Current Implementation: Hsigmoid(x) = min(max((x + 3) / 6, 0), 1).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "esnet = ESNet()\n",
    "print(esnet.out_ixs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abbf5657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([1, 96, 40, 40]), torch.Size([1, 192, 20, 20]), torch.Size([1, 384, 10, 10])]\n"
     ]
    }
   ],
   "source": [
    "esnet.stage_out_channels\n",
    "test_input = torch.from_numpy(np.random.rand(1, 3, 320, 320).astype(np.float32))\n",
    "test_outputs = esnet(test_input)\n",
    "print([a.shape for a in test_outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def6ae8f",
   "metadata": {},
   "source": [
    "TODO: Factor inverted residual blocks into this codebase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eb3d4b",
   "metadata": {},
   "source": [
    "## Neck: CSPPAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68e4558b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([1, 128, 40, 40]), torch.Size([1, 128, 20, 20]), torch.Size([1, 128, 10, 10])]\n"
     ]
    }
   ],
   "source": [
    "c = ChannelEqualiser([96, 192, 384], 128)\n",
    "channel_eq_outputs = c(test_outputs)\n",
    "print([c.shape for c in channel_eq_outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0e270a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 100, 100])\n"
     ]
    }
   ],
   "source": [
    "test_input = torch.from_numpy(np.random.rand(1, 32, 100, 100).astype(np.float32))\n",
    "dbb = DarknetBottleneck(in_channels=32, out_channels=32)\n",
    "dbb_output = dbb(test_input)\n",
    "print(dbb_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0be0453f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 100, 100])\n"
     ]
    }
   ],
   "source": [
    "cspl = CSPLayer(32, 32)\n",
    "cspl_output = cspl(test_input)\n",
    "print(cspl_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00104fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([1, 96, 40, 40]), torch.Size([1, 96, 20, 20]), torch.Size([1, 96, 10, 10]), torch.Size([1, 96, 5, 5])]\n"
     ]
    }
   ],
   "source": [
    "csppan = CSPPAN(\n",
    "    in_channels=[96, 192, 384],\n",
    "    act_cfg=dict(type='HSwish'),\n",
    "    norm_cfg=dict(type='BN', requires_grad=True),\n",
    "    out_channels=96,\n",
    "    squeeze_ratio=1,\n",
    "    num_csp_blocks=1\n",
    ")\n",
    "csppan_outputs = csppan(test_outputs)\n",
    "print([t.shape for t in csppan_outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e983cd88",
   "metadata": {},
   "source": [
    "## Head: PicoDetHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e724cc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.models.dense_heads import AnchorFreeHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c2c4098",
   "metadata": {},
   "outputs": [],
   "source": [
    "AFH_callable = [d for d in dir(AnchorFreeHead) if callable(getattr(AnchorFreeHead, d))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5af84f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv.cnn import DepthwiseSeparableConvModule, ConvModule\n",
    "\n",
    "@dataclass\n",
    "class PicoDetHead(BaseModule):\n",
    "    \"\"\"\n",
    "    Head of PP-PicoDet (v1)\n",
    "    \n",
    "    GFL: generalised focal loss \n",
    "    VFL: varifocal loss (classification loss)\n",
    "    DFL: distribution focal loss (localisation loss)\n",
    "    \n",
    "    \"\"\"\n",
    "    num_classes: int = Field(\n",
    "        description=\"Number of categories excluding the background category\"\n",
    "    )\n",
    "    in_channels: int = Field(\n",
    "        description=\"Number of channels in the input feature map\"\n",
    "    )\n",
    "    feat_channels: int = Field(\n",
    "        default=96,\n",
    "        description=\"Number of hidden channels in stacking convs\"\n",
    "    )\n",
    "    stacked_convs: int = Field(\n",
    "        default=2,\n",
    "        description=\"Number of stacked convolutions in the head\"\n",
    "    )\n",
    "    strides: tuple[int] = Field(\n",
    "        default=(8, 16, 32, 64),\n",
    "        description=\"Downsample factor of each feature map\"\n",
    "    )\n",
    "    use_depthwise: bool = Field(\n",
    "        default=True,\n",
    "        description=\"Enable depthwise-separable convolutions\"\n",
    "    )\n",
    "    kernel_size: int = Field(default=5, description=\"Kernel size of conv layers\")\n",
    "    share_cls_reg: bool = Field(\n",
    "        default=True,\n",
    "        description=\"Flag to share weights between regression and classificaiton branches\"\n",
    "    )\n",
    "    sigmoid_classifier: bool = Field(\n",
    "        default=True,\n",
    "        description=\"Whether sigmoid loss will be used. This will reduce output channels by 1.\"\n",
    "    )\n",
    "    # I think this is the number of objects allowed assigned to the same prior point?\n",
    "    reg_max: int = Field(\n",
    "        default=7,\n",
    "        description=\"Max value of integral set {0, ..., reg_max} in DFL setting.\"\n",
    "    )\n",
    "    conv_cfg: dict = Field(\n",
    "        default=None,\n",
    "        description=\"Config dict for 2D convolution layer.\"\n",
    "    )\n",
    "    norm_cfg: dict = Field(\n",
    "        default_factory=lambda: dict(type='BN', requires_grad=True),\n",
    "        description=\"Config dict for 2D convolution layer.\"\n",
    "    ) \n",
    "    act_cfg: dict = Field(\n",
    "        default_factory=lambda: dict(type='HSwish'),\n",
    "        description=\"Config dict for activation layer.\"\n",
    "    )    \n",
    "    init_cfg: Optional[dict] = Field(\n",
    "        default=None, description=\"Weight initialisation config dict\"\n",
    "    )    \n",
    "\n",
    "    def __post_init__(self):\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def ConvModule(self):\n",
    "        return DepthwiseSeparableConvModule if self.use_depthwise else ConvModule\n",
    "    \n",
    "    @property\n",
    "    def output_channels_classification(self):\n",
    "        return self.num_classes + (not self.sigmoid_classifier)\n",
    "    \n",
    "    def __post_init_post_parse__(self):\n",
    "        super().__init__(self.init_cfg)\n",
    "        # build conv layers for interpreting neck outputs - classification\n",
    "        self.cls_convs = nn.ModuleList([self._build_convs() for _ in self.strides])\n",
    "        # regression (optional, if not sharing weights from classification)\n",
    "        self.reg_convs = nn.ModuleList([\n",
    "            self._build_convs() for _ in self.strides if not self.share_cls_reg\n",
    "        ])\n",
    "        # generalised focal loss head classification\n",
    "        self.output_channels_regression = 4 * (self.reg_max + 1)\n",
    "        # if sharing the weights between classification and regression,\n",
    "        # the GFL head will calculate both together then split\n",
    "        self.gfl_classification_conv_out_channels = self.output_channels_classification\n",
    "        if self.share_cls_reg:\n",
    "            # C + (x1, x2, y1, y2 + ?)\n",
    "            self.gfl_classification_conv_out_channels += self.output_channels_regression\n",
    "        # classification\n",
    "        self.gfl_classification_convs = nn.ModuleList([\n",
    "            nn.Conv2d(\n",
    "                in_channels=self.feat_channels,\n",
    "                out_channels=self.gfl_classification_conv_out_channels, \n",
    "                kernel_size=1,\n",
    "                padding=0\n",
    "            )\n",
    "            for _ in self.strides\n",
    "        ])\n",
    "        # regression (optional, if weights shared done together by classificaiton conv)\n",
    "        self.gfl_regression_convs = nn.ModuleList([\n",
    "            nn.Conv2d(\n",
    "                in_channels=self.feat_channels,\n",
    "                out_channels=self.output_channels_regression,\n",
    "                kernel_size=1,\n",
    "                padding=0\n",
    "            )\n",
    "            for _ in self.strides\n",
    "            if not self.share_cls_reg\n",
    "        ])\n",
    "    \n",
    "    def _build_convs(self):\n",
    "        \"\"\"Create a list of self.stacked_convs conv blocks\"\"\"\n",
    "        chn = (lambda i: self.in_channels if not i else self.feat_channels)\n",
    "        return nn.ModuleList([\n",
    "            self.ConvModule(\n",
    "                in_channels=chn(i),\n",
    "                out_channels=self.feat_channels,\n",
    "                kernel_size=self.kernel_size,\n",
    "                stride=1,\n",
    "                padding=(self.kernel_size-1) // 2,\n",
    "                act_cfg=self.act_cfg,\n",
    "                norm_cfg=self.norm_cfg,\n",
    "                bias=self.norm_cfg is None\n",
    "            )\n",
    "            for i in range(self.stacked_convs)\n",
    "        ])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ee28bb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = PicoDetHead(in_channels=96, num_classes=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7381280f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PicoDetHead(num_classes=80, in_channels=96, feat_channels=96, stacked_convs=2, strides=(8, 16, 32, 64), use_depthwise=True, kernel_size=5, share_cls_reg=True, sigmoid_classifier=True, reg_max=7, conv_cfg=None, norm_cfg={'type': 'BN', 'requires_grad': True}, act_cfg={'type': 'HSwish'}, init_cfg=None)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5939ac13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
